{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "## Assignment 3 (part 1). Recurrent Neural Networks for Language Modeling\n",
    "\n",
    "**Total points**: 30\n",
    "\n",
    "In this assignment, you will train a vanilla RNN language model on《论语》and evaluate its perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary: 1352\n"
     ]
    }
   ],
   "source": [
    "input_file = 'lunyu_20chapters.txt'\n",
    "\n",
    "from util import CorpusReader\n",
    "corpus = CorpusReader(inputFileName=input_file, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "# Modify word2id to make 0 as the padding token '[PAD]', and increase the index of all other words by 1\n",
    "# Modify the id2word list to make the first word '[PAD]' as well\n",
    "# Hint: Both word2id and id2word in utils.CorpusReader are dict objects\n",
    "word2id = {}\n",
    "word2id['[PAD]'] = 0\n",
    "for word, id in corpus.word2id.items():\n",
    "    word2id[word] = id + 1\n",
    "\n",
    "id2word = {}\n",
    "id2word[0] = '[PAD]'\n",
    "for id, word in corpus.id2word.items():\n",
    "    id2word[id + 1] = word\n",
    "### END YOUR CODE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2word: [(0, '[PAD]'), (1, '，'), (2, '子'), (3, '。'), (4, '：')]\n",
      "word2id: [('[PAD]', 0), ('，', 1), ('子', 2), ('。', 3), ('：', 4)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test result\n",
    "print('id2word:', sorted(list(id2word.items()), key=lambda x: x[0])[:5])\n",
    "print('word2id:', sorted(list(word2id.items()), key=lambda x: x[1])[:5])\n",
    "\n",
    "# You should expect to see:\n",
    "# id2word: [(0, '[PAD]'), (1, '，'), (2, '子'), (3, '。'), (4, '：')]\n",
    "# word2id: [('[PAD]', 0), ('，', 1), ('子', 2), ('。', 3), ('：', 4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 393])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    max_len = max([len(line.strip()) for line in lines])\n",
    "line_words = [list(line.strip()) for line in lines]\n",
    "seq_ids = [torch.tensor([word2id.get(word, 0) for word in words]) for words in line_words]\n",
    "seq_lens = torch.tensor([len(ids) for ids in seq_ids])\n",
    "seq_ids_padded = nn.utils.rnn.pad_sequence(seq_ids, batch_first=True)\n",
    "seq_ids_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_lunyu = nn.Embedding(len(word2id), 50) # vocab_size, embedding_dim\n",
    "rnn_lunyu = nn.RNN(50, 100, batch_first=True)\n",
    "seq_embs = embedding_lunyu(seq_ids_padded)\n",
    "seq_embs_packed = nn.utils.rnn.pack_padded_sequence(seq_embs, seq_lens, batch_first=True, enforce_sorted=False)\n",
    "out_packed, _ = rnn_lunyu(seq_embs_packed)\n",
    "out_unpacked, _ = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length:  393\n",
      "seq_ids_padded: torch.Size([512, 393])\n",
      "seq_embs: torch.Size([512, 393, 50])\n",
      "out_unpacked: torch.Size([512, 393, 100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test result\n",
    "print('max length: ', max_len)\n",
    "print('seq_ids_padded:', seq_ids_padded.size())\n",
    "print('seq_embs:', seq_embs.size())\n",
    "print('out_unpacked:', out_unpacked.size())\n",
    "\n",
    "# You should expect to see:\n",
    "# seq_ids_padded: torch.Size([512, 393])\n",
    "# seq_embs: torch.Size([512, 393, 50])\n",
    "# out_unpacked: torch.Size([512, 393, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,   5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,\n",
       "         15, 267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,\n",
       "         30,   9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_ids_padded[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_padded = torch.zeros_like(seq_ids_padded)\n",
    "padding_id = 0\n",
    "\n",
    "for i in range(seq_ids_padded.size(0)):\n",
    "    targets_padded[i, :-1] = seq_ids_padded[i, 1:] # Shift the sequence to the left by 1\n",
    "    targets_padded[i, -1] = padding_id # Set the last token to be the padding token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets_padded: torch.Size([512, 393])\n",
      "last column of targets_padded: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "seq_ids_padded[0][:50]: tensor([  2,   5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,\n",
      "         15, 267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,\n",
      "         30,   9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n",
      "targets_padded[0][:50]: tensor([  5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,  15,\n",
      "        267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,  30,\n",
      "          9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n"
     ]
    }
   ],
   "source": [
    "# Test result\n",
    "print('targets_padded:', targets_padded.size())\n",
    "print('last column of targets_padded:', targets_padded[:, -1][:10])\n",
    "\n",
    "print('seq_ids_padded[0][:50]:', seq_ids_padded[0][:50])\n",
    "print('targets_padded[0][:50]:', targets_padded[0][:50])\n",
    "\n",
    "# You should expect to see:\n",
    "# targets_padded: torch.Size([512, 393])\n",
    "# last column of targets_padded: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets_padded: torch.Size([512, 393])\n",
      "last column of targets_padded[:20]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "seq_ids_padded[0][:50]: tensor([  2,   5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,\n",
      "         15, 267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,\n",
      "         30,   9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n",
      "targets_padded[0][:50]: tensor([  5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,  15,\n",
      "        267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,  30,\n",
      "          9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n"
     ]
    }
   ],
   "source": [
    "train_seq_ids = seq_ids\n",
    "train_seq_lens = seq_lens\n",
    "\n",
    "### START YOUR CODE ###\n",
    "targets_padded = torch.zeros_like(seq_ids_padded)\n",
    "padding_id = 0\n",
    "\n",
    "for i in range(seq_ids_padded.size(0)):\n",
    "    targets_padded[i, :-1] = seq_ids_padded[i, 1:] # Shift the sequence to the left by 1\n",
    "    targets_padded[i, -1] = padding_id # Set the last token to be the padding token\n",
    "\n",
    "### END YOUR CODE ###\n",
    "\n",
    "# Test result\n",
    "print('targets_padded:', targets_padded.size())\n",
    "print('last column of targets_padded[:20]:', targets_padded[:, -1][:20])\n",
    "\n",
    "print('seq_ids_padded[0][:50]:', seq_ids_padded[0][:50])\n",
    "print('targets_padded[0][:50]:', targets_padded[0][:50])\n",
    "# You should expect to see:\n",
    "# targets_padded: torch.Size([16, 85])\n",
    "# last column of targets_padded: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('embedding_emb50_neg10_win1.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1352, 50), numpy.ndarray)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.vectors.shape, type(word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1353, 50), array([0., 0., 0., 0., 0.]), '[PAD]')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the pad token to the word vectors (index 0)\n",
    "vec = word_vectors.vectors\n",
    "vec = np.vstack((np.zeros((1,50)), vec)) # for the pad token\n",
    "vec.shape, vec[0][:5], id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.Embedding(vocab_size, emb_size)\n",
    "embedding_w2v = nn.Embedding.from_pretrained(torch.Tensor(vec), padding_idx=0)\n",
    "# add '[PAD]' to the embedding matrix\n",
    "embedding_w2v.weight.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1353, 50])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_rand = nn.Embedding(len(word2id), 50, padding_idx=0)\n",
    "embedding_rand.weight.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.9306,  0.4925, -0.6729, -1.6648,  0.3644], grad_fn=<SliceBackward0>),\n",
       " tensor([ 0.1959,  0.1646,  0.0488, -0.2016, -0.2239]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_rand.weight[5][:5], embedding_w2v.weight[5][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 1353)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_w2v.num_embeddings, embedding_rand.num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify word2id to make 0 as the padding token '[PAD]', and increase the index of all other words by 1\n",
    "# Modify the id2word list to make the first word '[PAD]' as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "`forward` method takes the word id sequences and sequence lengths as inputs, and return the logits or log probabilities from RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, embedding: nn.Embedding ,**kwargs):\n",
    "        super(RNNLM, self).__init__()\n",
    "        self.embedding = embedding\n",
    "        self.rnn = nn.RNN(embedding.embedding_dim, hidden_size=100, batch_first=True)\n",
    "        self.fc = nn.Linear(100, len(word2id))\n",
    "        \n",
    "\n",
    "    def forward(self, seq, seq_lens): # pass in raw word ids and sequence lengths\n",
    "        padded_seqs = nn.utils.rnn.pad_sequence(seq, batch_first=True)\n",
    "        padded_embs = self.embedding(padded_seqs)\n",
    "        packed_embs = nn.utils.rnn.pack_padded_sequence(padded_embs, seq_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out_packed, _ = self.rnn(packed_embs)\n",
    "        out_unpacked, _ = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)\n",
    "        # print(out_unpacked.size()) # ([512, 393, 100])\n",
    "        logits = self.fc(out_unpacked)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model_rand = RNNLM(embedding_rand)\n",
    "model_w2v = RNNLM(embedding_w2v)\n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss(ignore_index=0, reduction='none')\n",
    "optimizer_rand = optim.Adam(model_rand.parameters(), lr=learning_rate)\n",
    "optimizer_w2v = optim.Adam(model_w2v.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: RNNLM, seq, seq_len, targets_padded, loss_fn, optimizer, n_epochs=10):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        log_probs = model.forward(seq, seq_len)\n",
    "\n",
    "        loss = loss_fn(log_probs.view(-1, len(word2id)), targets_padded.view(-1))\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        perplexity = torch.exp(loss)        \n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}, Perplexity: {perplexity.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: RNNLM, seq, seq_len, targets_padded, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        log_probs = model.forward(seq, seq_len)\n",
    "        loss = loss_fn(log_probs.view(-1, len(word2id)), targets_padded.view(-1))\n",
    "        loss = loss.mean()\n",
    "        perplexity = torch.exp(loss)\n",
    "        print(f'Evaluation Loss: {loss.item()}')\n",
    "        print(f'Perplexity: {perplexity.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.6947778463363647, Perplexity: 2.0032639503479004\n",
      "Epoch 2/25, Loss: 0.6264045238494873, Perplexity: 1.8708717823028564\n",
      "Epoch 3/25, Loss: 0.4940985441207886, Perplexity: 1.6390200853347778\n",
      "Epoch 4/25, Loss: 0.48375776410102844, Perplexity: 1.6221586465835571\n",
      "Epoch 5/25, Loss: 0.46546778082847595, Perplexity: 1.592759132385254\n",
      "Epoch 6/25, Loss: 0.4524214267730713, Perplexity: 1.57211434841156\n",
      "Epoch 7/25, Loss: 0.43826037645339966, Perplexity: 1.5500084161758423\n",
      "Epoch 8/25, Loss: 0.42525094747543335, Perplexity: 1.529974341392517\n",
      "Epoch 9/25, Loss: 0.41341638565063477, Perplexity: 1.5119744539260864\n",
      "Epoch 10/25, Loss: 0.4031398594379425, Perplexity: 1.496516227722168\n",
      "Epoch 11/25, Loss: 0.39184197783470154, Perplexity: 1.4797039031982422\n",
      "Epoch 12/25, Loss: 0.3811172544956207, Perplexity: 1.4639192819595337\n",
      "Epoch 13/25, Loss: 0.37143948674201965, Perplexity: 1.4498201608657837\n",
      "Epoch 14/25, Loss: 0.3617735803127289, Perplexity: 1.4358737468719482\n",
      "Epoch 15/25, Loss: 0.352710485458374, Perplexity: 1.4229191541671753\n",
      "Epoch 16/25, Loss: 0.3440249264240265, Perplexity: 1.410613775253296\n",
      "Epoch 17/25, Loss: 0.3359003961086273, Perplexity: 1.3991996049880981\n",
      "Epoch 18/25, Loss: 0.3278670012950897, Perplexity: 1.3880043029785156\n",
      "Epoch 19/25, Loss: 0.3203740119934082, Perplexity: 1.3776428699493408\n",
      "Epoch 20/25, Loss: 0.31306684017181396, Perplexity: 1.3676129579544067\n",
      "Epoch 21/25, Loss: 0.3060336709022522, Perplexity: 1.3580280542373657\n",
      "Epoch 22/25, Loss: 0.29918259382247925, Perplexity: 1.3487558364868164\n",
      "Epoch 23/25, Loss: 0.2924761474132538, Perplexity: 1.3397407531738281\n",
      "Epoch 24/25, Loss: 0.28618311882019043, Perplexity: 1.331336259841919\n",
      "Epoch 25/25, Loss: 0.27975723147392273, Perplexity: 1.3228086233139038\n"
     ]
    }
   ],
   "source": [
    "train(model_rand, seq_ids, seq_lens, targets_padded, loss_fn, optimizer_rand, n_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22, Loss: 0.6943380832672119, Perplexity: 2.002383232116699\n",
      "Epoch 2/22, Loss: 0.6428998112678528, Perplexity: 1.9019882678985596\n",
      "Epoch 3/22, Loss: 0.5384312868118286, Perplexity: 1.7133170366287231\n",
      "Epoch 4/22, Loss: 0.5130017399787903, Perplexity: 1.6702975034713745\n",
      "Epoch 5/22, Loss: 0.5160813331604004, Perplexity: 1.675449252128601\n",
      "Epoch 6/22, Loss: 0.5080342888832092, Perplexity: 1.6620209217071533\n",
      "Epoch 7/22, Loss: 0.49919945001602173, Perplexity: 1.6474019289016724\n",
      "Epoch 8/22, Loss: 0.4922601878643036, Perplexity: 1.636009693145752\n",
      "Epoch 9/22, Loss: 0.4862425923347473, Perplexity: 1.6261944770812988\n",
      "Epoch 10/22, Loss: 0.4819709360599518, Perplexity: 1.6192626953125\n",
      "Epoch 11/22, Loss: 0.4762839078903198, Perplexity: 1.6100801229476929\n",
      "Epoch 12/22, Loss: 0.47073444724082947, Perplexity: 1.6011697053909302\n",
      "Epoch 13/22, Loss: 0.46530359983444214, Perplexity: 1.5924975872039795\n",
      "Epoch 14/22, Loss: 0.45995819568634033, Perplexity: 1.584007740020752\n",
      "Epoch 15/22, Loss: 0.4556095004081726, Perplexity: 1.577134370803833\n",
      "Epoch 16/22, Loss: 0.45474252104759216, Perplexity: 1.5757676362991333\n",
      "Epoch 17/22, Loss: 0.44912397861480713, Perplexity: 1.566938877105713\n",
      "Epoch 18/22, Loss: 0.440377801656723, Perplexity: 1.5532939434051514\n",
      "Epoch 19/22, Loss: 0.4365755021572113, Perplexity: 1.5473990440368652\n",
      "Epoch 20/22, Loss: 0.43047210574150085, Perplexity: 1.5379834175109863\n",
      "Epoch 21/22, Loss: 0.424774706363678, Perplexity: 1.5292458534240723\n",
      "Epoch 22/22, Loss: 0.4201872944831848, Perplexity: 1.5222465991973877\n"
     ]
    }
   ],
   "source": [
    "train(model_w2v, seq_ids, seq_lens, targets_padded, loss_fn, optimizer_w2v, n_epochs=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Perplexity (on training data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the perplexity by exponentiating the average loss per sequence.\n",
    "\n",
    "See the documentation here: https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 0.27371081709861755\n",
      "Perplexity: 1.314834475517273\n"
     ]
    }
   ],
   "source": [
    "# random embedding\n",
    "evaluate(model_rand, seq_ids, seq_lens, targets_padded, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 0.413811594247818\n",
      "Perplexity: 1.512572169303894\n"
     ]
    }
   ],
   "source": [
    "# word2vec embedding\n",
    "evaluate(model_w2v, seq_ids, seq_lens, targets_padded, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence(model, seq, max_length=20):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        current_tokens = seq\n",
    "        for _ in range(max_length):\n",
    "            current_tokens_tensor = torch.tensor([[word2id[word] for word in current_tokens]])\n",
    "            seq_lens = torch.tensor([len(current_tokens)])\n",
    "            # 调用模型，获取下一个单词的概率分布\n",
    "            log_probs = model(current_tokens_tensor, seq_lens)\n",
    "            # 从概率分布中采样下一个单词的索引\n",
    "            next_word_index = torch.argmax(log_probs[:, -1, :], dim=-1).item()\n",
    "            next_word = id2word[next_word_index]\n",
    "            current_tokens.append(next_word)\n",
    "            if next_word == '。':\n",
    "                break\n",
    "        return ''.join(current_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['天','下']\n",
    "max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天下，子曰：君子曰：君子曰：君子曰：君子曰：\n"
     ]
    }
   ],
   "source": [
    "print(get_sentence(model_w2v, seq, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['子','曰']\n",
    "max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'子曰：君子不能，不可以为之，不可以为之，不可'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence(model_rand, seq, max_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
