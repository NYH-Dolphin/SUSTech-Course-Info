{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2: Bi-LSTM-based Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from dep_utils import conll_reader, DependencyTree, DependencyEdge\n",
    "import copy\n",
    "from pprint import pprint\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read Data and Generate Training Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train.conll:\n",
      "39832 trees read.\n",
      "In dev.conll:\n",
      "1700 trees read.\n",
      "In test.conll:\n",
      "2416 trees read.\n"
     ]
    }
   ],
   "source": [
    "print('In train.conll:')\n",
    "with open('data/train.conll') as f:\n",
    "    train_trees = list(conll_reader(f))\n",
    "print(f'{len(train_trees)} trees read.')\n",
    "\n",
    "print('In dev.conll:')\n",
    "with open('data/dev.conll') as f:\n",
    "    dev_trees = list(conll_reader(f))\n",
    "print(f'{len(dev_trees)} trees read.')\n",
    "\n",
    "print('In test.conll:')\n",
    "with open('data/test.conll') as f:\n",
    "    test_trees = list(conll_reader(f))\n",
    "print(f'{len(test_trees)} trees read.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The top of stack is `stack[-1]`\n",
    "- The front of buffer is `buffer[-1]`\n",
    "- `deps` represents the currently found dependencies\n",
    "  - It is a list of `(parent, child, relation)` triples, where `parent` and `child` are integer IDs and `relation` is a string (the dependency label).\n",
    "- The `shift` methods moves the front of the buffer to the top of the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(object):\n",
    "    def __init__(self, sentence=[]):\n",
    "        self.stack = []\n",
    "        self.buffer = []\n",
    "        if sentence:\n",
    "            self.buffer = list(reversed(sentence))\n",
    "        self.deps = set()\n",
    "\n",
    "    def shift(self):\n",
    "        assert len(self.buffer) > 0\n",
    "        self.stack.append(self.buffer.pop())\n",
    "\n",
    "    def left_arc(self, label):\n",
    "        assert len(self.stack) >= 2\n",
    "        self.deps.add((self.stack[-1], self.stack[-2], label))\n",
    "        self.stack.pop(-2)\n",
    "\n",
    "    def right_arc(self, label):\n",
    "        assert len(self.stack) >= 2\n",
    "        self.deps.add((self.stack[-2], self.stack[-1], label))\n",
    "        self.stack.pop(-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"({},{},{})\".format(self.stack, self.buffer, self.deps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training data from a dependency tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootDummy(object):\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.id = 0\n",
    "        self.deprel = None\n",
    "    def __repr__(self):\n",
    "        return \"<ROOT>\"\n",
    "\n",
    "\n",
    "def get_training_instances(dep_tree: DependencyTree) -> List[Tuple[State, Tuple[str, str]]]:\n",
    "    deprels = dep_tree.deprels\n",
    "\n",
    "    word_ids = list(deprels.keys())\n",
    "    state = State(word_ids)\n",
    "    state.stack.append(0) # ROOT\n",
    "\n",
    "    childcount = defaultdict(int)\n",
    "    for _, rel in deprels.items():\n",
    "        childcount[rel.head] += 1\n",
    "\n",
    "    seq = []\n",
    "    while len(state.buffer) > 0 or len(state.stack) > 1:\n",
    "        if state.stack[-1] == 0:\n",
    "            seq.append((copy.deepcopy(state), (\"shift\", None)))\n",
    "            state.shift()\n",
    "            continue\n",
    "        \n",
    "        stack_top1 = deprels[state.stack[-1]]\n",
    "        if state.stack[-2] == 0:\n",
    "            stack_top2 = RootDummy()\n",
    "        else:\n",
    "            stack_top2 = deprels[state.stack[-2]]\n",
    "\n",
    "        # Decide transition action\n",
    "        ### START YOUR CODE ###\n",
    "        try:\n",
    "            if stack_top2.head == stack_top1.id : # Left-Arc, top1 -> top2\n",
    "                childcount[stack_top1.id] -= 1\n",
    "                seq.append((copy.deepcopy(state), (\"left_arc\", stack_top2.deprel)))\n",
    "                state.left_arc(stack_top2.deprel)\n",
    "            elif stack_top1.head == stack_top2.id and childcount[stack_top1.id] == 0: # Right-Arc, top2 -> top1\n",
    "                childcount[stack_top2.id] -= 1\n",
    "                seq.append((copy.deepcopy(state), (\"right_arc\", stack_top1.deprel)))\n",
    "                state.right_arc(stack_top1.deprel)\n",
    "            else: # Shift\n",
    "                seq.append((copy.deepcopy(state), (\"shift\", None)))\n",
    "                state.shift()\n",
    "        except:\n",
    "            return seq\n",
    "        ### END YOUR CODE ###\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "pos2id = {}\n",
    "word2id['<PAD>'] = 0\n",
    "pos2id['<PAD>'] = 0\n",
    "def get_vocabs(trees: List[DependencyTree]):\n",
    "    for tree in trees:\n",
    "        word = tree.words()\n",
    "        pos = tree.pos()\n",
    "        for w in word:\n",
    "            if w is None:\n",
    "                continue\n",
    "            if w not in word2id:\n",
    "                word2id[w] = len(word2id)\n",
    "        for p in pos:\n",
    "            if p is None:\n",
    "                continue\n",
    "            if p not in pos2id:\n",
    "                pos2id[p] = len(pos2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_vocab: 46351 words\n",
      "pos_vocab: 48 pos tags\n"
     ]
    }
   ],
   "source": [
    "get_vocabs(train_trees)\n",
    "get_vocabs(dev_trees)\n",
    "get_vocabs(test_trees)\n",
    "\n",
    "word2id['<NULL>'] = len(word2id)\n",
    "pos2id['<NULL>'] = len(pos2id)\n",
    "word2id['<ROOT>'] = len(word2id)\n",
    "pos2id['<ROOT>'] = len(pos2id)\n",
    "\n",
    "\n",
    "print(f'word_vocab: {len(word2id)} words')\n",
    "print(f'pos_vocab: {len(pos2id)} pos tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Action Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number fo unique relations: 39\n",
      "dict_keys(['case', 'det', 'compound', 'nummod', 'nmod', 'punct', 'nmod:poss', 'amod', 'nsubj', 'dep', 'dobj', 'cc', 'conj', 'nsubjpass', 'acl', 'auxpass', 'advmod', 'root', 'ccomp', 'mark', 'xcomp', 'nmod:tmod', 'appos', 'nmod:npmod', 'aux', 'cop', 'neg', 'acl:relcl', 'advcl', 'mwe', 'det:predet', 'csubj', 'parataxis', 'compound:prt', 'iobj', 'expl', 'cc:preconj', 'discourse', 'csubjpass'])\n"
     ]
    }
   ],
   "source": [
    "rel_vocab = {}\n",
    "\n",
    "for t in train_trees+dev_trees+test_trees:\n",
    "    for e in t.deprels.values():\n",
    "        if e.deprel not in rel_vocab:\n",
    "            rel_vocab[e.deprel] = len(rel_vocab)\n",
    "\n",
    "# Test results\n",
    "print('Total number fo unique relations:', len(rel_vocab))\n",
    "print(rel_vocab.keys())\n",
    "\n",
    "# You should expect to see the following output:\n",
    "# Total number fo unique relations: 39\n",
    "# {'nummod', 'root', 'nmod:tmod', 'nmod', 'punct', 'expl', 'auxpass', 'neg', 'nsubjpass', 'appos' ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action vocab\n",
    "action2id = {}\n",
    "action2id[('shift',None)] = len(action2id)\n",
    "for rel in rel_vocab.keys():\n",
    "    if rel != 'root':\n",
    "        action2id[(\"left_arc\", rel)] = len(action2id)\n",
    "        action2id[(\"right_arc\", rel)] = len(action2id)\n",
    "action2id[(\"right_arc\", 'root')] = len(action2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action2id) # (39-1)*2 + 1(right_arc, root) + 1(shift, none) = 78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For actual training step, you need to post-process the data to convert each relation tuple to an integer index. \n",
    "- We have 39 unique dependency relations in the data, including `ROOT`. Considering `ROOT` only appears as the head in a `right_arc` action, we have $(39-1)\\times 2 + 1 = 77$ possible actions in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "\n",
    "- https://aclanthology.org/Q16-1023/\n",
    "- https://github.com/s-kill/Simple-and-Accurate-Dependency-Parsing-Using-Bidirectional-LSTM-Feature-Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BiLSTM Feature Extractor\n",
    "- $x_i = e(w_i)⨁e(t_i)$\n",
    "- $v_i = BiLSTM(x_i, i)$\n",
    "- $input = v_{s_2}⨁v_{s_1}⨁v_{s_0}⨁v_{b_0}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMFeatureExtractor():\n",
    "    def __init__(self):\n",
    "        print('LSTM FeatureExtractor')\n",
    "\n",
    "    def get_input_representation(self, state):\n",
    "        features = []\n",
    "        # Index of vs2, vs1, vs0, bs0 in the sequence\n",
    "        for s in range(-3, 0): # top 3 words on the stack\n",
    "            if abs(s) <= len(state.stack):\n",
    "                sw_id = state.stack[s]\n",
    "                features.append(sw_id) # 0 is ROOT\n",
    "            else:\n",
    "                features.append(-1)\n",
    "\n",
    "        b = -1 # top 1 word on the buffer\n",
    "        if abs(b) <= len(state.buffer):\n",
    "            bw_id = state.buffer[b]\n",
    "            features.append(bw_id)\n",
    "        else:\n",
    "            features.append(-1)\n",
    "\n",
    "        return torch.LongTensor(features).to(device)\n",
    "\n",
    "    def get_output_representation(self, action):\n",
    "        return torch.tensor(action2id[action], dtype=torch.long).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dep_trees: List[DependencyTree],extractor: LSTMFeatureExtractor):\n",
    "    feats = []\n",
    "    outputs = []\n",
    "    words = []\n",
    "    pos = []\n",
    "    feats = []\n",
    "    for i, tree in enumerate(dep_trees):\n",
    "        tree_words = tree.words()\n",
    "        tree_pos = tree.pos()\n",
    "        instances = get_training_instances(tree)\n",
    "        if i % 1000 == 0:\n",
    "            print(f'{i}/{len(dep_trees)}')\n",
    "        # words and pos inputs for bilstm\n",
    "        word_ids = []\n",
    "        pos_ids = []\n",
    "        for w in tree_words:\n",
    "            if w is None: \n",
    "                # here the first element None is not in the inputs, when getting the hidden state h_i from BiLSTM\n",
    "                # given an index i, use (i-1) since i is relative index in the word sequence.\n",
    "                continue\n",
    "            word_ids.append(word2id[w])\n",
    "        for p in tree_pos:\n",
    "            if p is None:\n",
    "                continue\n",
    "            pos_ids.append(pos2id[p])\n",
    "        word_ids = torch.LongTensor(word_ids).to(device)\n",
    "        pos_ids = torch.LongTensor(pos_ids).to(device)\n",
    "        for state, action in instances:\n",
    "            # convert to torch tensor\n",
    "            words.append(word_ids) # variable length\n",
    "            pos.append(pos_ids) # variable length\n",
    "            feats.append(extractor.get_input_representation(state)) # fixed length\n",
    "            outputs.append(extractor.get_output_representation(action)) # fixed length\n",
    "\n",
    "    return words, pos, torch.stack(feats).to(device), torch.stack(outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM FeatureExtractor\n",
      "0/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  7, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 10, 26, 27, 28, 29, 25, 20, 30,  6, 31,\n",
       "         25, 32, 33, 34, 35, 25, 36, 37, 38, 39, 40, 41, 42], device='cuda:0'),\n",
       " tensor([ 1,  2,  3,  4,  5,  1,  6,  2,  5,  7,  1,  3,  8,  3,  3,  9,  6, 10,\n",
       "         11, 12,  2,  5,  1,  3,  3, 13,  7,  5, 14, 11, 15, 13,  2,  5,  1,  3,\n",
       "         13, 10,  1,  3,  3, 13, 16, 17, 10, 18,  3,  3, 19], device='cuda:0'),\n",
       " tensor([-1, -1,  0,  1], device='cuda:0'),\n",
       " tensor(0, device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the FeatureExtractor\n",
    "w,p,f,l = process(train_trees[:2],LSTMFeatureExtractor())\n",
    "w[0], p[0], f[0], l[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BiLSTM Oracle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46351, 78)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dim = len(word2id)\n",
    "pos_dim = len(pos2id)\n",
    "word_emb_dim = 50\n",
    "pos_emb_dim = 10\n",
    "feature_len = 4\n",
    "out_dim = len(action2id)\n",
    "emb_dim = 50\n",
    "lstm_hidden_dim = 30\n",
    "mlp_hidden_dim = 100\n",
    "word_dim, out_dim\n",
    "# word_emb + pos_emb = 2 * lstm_hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMOracle(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            feature_len: int,\n",
    "            word_dim: int,\n",
    "            pos_dim: int,\n",
    "            word_emb_dim: int,\n",
    "            pos_emb_dim: int,\n",
    "            out_dim: int,\n",
    "            lstm_hidden_dim=50,\n",
    "            mlp_hidden_dim=100\n",
    "            # word_emb_dim + pos_emb_dim = 2 * lstm_hidden_dim, 因为feature要拼起来\n",
    "            ):\n",
    "        assert word_emb_dim+pos_emb_dim == 2*lstm_hidden_dim\n",
    "        super(BiLSTMOracle, self).__init__()\n",
    "        self.word_embedding = nn.Embedding(num_embeddings=word_dim, embedding_dim=word_emb_dim)\n",
    "        self.pos_embedding = nn.Embedding(num_embeddings=pos_dim, embedding_dim=pos_emb_dim)\n",
    "        self.bilstm = nn.LSTM(word_emb_dim + pos_emb_dim, lstm_hidden_dim, batch_first=True, bidirectional = True)\n",
    "        # output: [batch_size, seq_len, lstm_hidden_dim]\n",
    "        self.mlp = nn.Sequential(\n",
    "            # nn.Flatten(),\n",
    "            # bilstm output is: 2 (bidirection) * (word_emb_dim + pos_emb_dim) * 4 (3 on stack, 1 on buffer)\n",
    "            nn.Linear(feature_len*(word_emb_dim + pos_emb_dim), mlp_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_dim, out_dim),\n",
    "        )\n",
    "        # softmax layer is calculated outside\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.word_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.pos_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        for layer in self.mlp:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.uniform_(-initrange, initrange)\n",
    "                layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, word_ids, pos_ids, features): # word_ids: [batch_size, seq_len], pos_ids: [batch_size, seq_len]\n",
    "            word_emb = self.word_embedding(word_ids) # [batch_size, seq_len, 50]\n",
    "            pos_emb = self.pos_embedding(pos_ids) # [batch_size, seq_len, 10]\n",
    "            \n",
    "            emb = torch.cat((word_emb, pos_emb), dim=2) # [batch_size, seq_len, 50 + 10]\n",
    "            lstm_out, _ = self.bilstm(emb) # [batch_size, seq_len, 2 * lstm_hidden_dim]\n",
    "            mlp_input = [] # [batch_size, 4, lstm_hidden_dim * 2]\n",
    "            for i, row in enumerate(features):\n",
    "                row_input = []\n",
    "                for j, feat_idx in enumerate(row):\n",
    "                    if feat_idx == -1:  # NULL\n",
    "                        row_input.append(torch.cat((self.word_embedding(torch.tensor(word2id['<NULL>']).to(device)), self.pos_embedding(torch.tensor(pos2id['<NULL>']).to(device))), dim=-1))\n",
    "                    elif feat_idx == 0:  # ROOT\n",
    "                        row_input.append(torch.cat((self.word_embedding(torch.tensor(word2id['<ROOT>']).to(device)), self.pos_embedding(torch.tensor(pos2id['<ROOT>']).to(device))), dim=-1))\n",
    "                    else:  # relative index in word sequence\n",
    "                        # the first None is not in the inputs, there is 1 offet\n",
    "                        # print(lstm_out[:, feat_idx - 1, :].shape) # [batch, lstm_hidden_dim]\n",
    "                        # print(lstm_out[:, feat_idx - 1, :][i].shape) # [lstm hidden dim]\n",
    "                        # hidden state at timestep feat_idx\n",
    "                        row_input.append(lstm_out[:, feat_idx - 1, :][i])\n",
    "                        # [batch_size, 2 * lstm_hidden_dim]\n",
    "                mlp_input.append(torch.stack(row_input))\n",
    "            \n",
    "            mlp_input = torch.stack(mlp_input, dim=0) # [batch_size, 4, lstm_hidden_dim * 2]\n",
    "            mlp_input = mlp_input.squeeze(1)\n",
    "            mlp_input = mlp_input.view(-1,mlp_input.size(1)*mlp_input.size(2)) # 从二维特征调整为一维 [batch, 4 * 2 * lstm_hidden_dim]\n",
    "            x = self.mlp(mlp_input) # [batch, num_class]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM FeatureExtractor\n",
      "0/1000\n"
     ]
    }
   ],
   "source": [
    "train_words, train_pos, train_feats, train_label = process(train_trees[:1000], LSTMFeatureExtractor())\n",
    "# this could take a while, using [:1000] as demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser(object): \n",
    "\n",
    "    def __init__(self, model: BiLSTMOracle, extractor: LSTMFeatureExtractor):\n",
    "        self.model = model\n",
    "        self.extractor = extractor\n",
    "        self.id2action = {v: k for k, v in action2id.items()}\n",
    "\n",
    "    def parse_sentence(self, words, pos):\n",
    "        state = State(range(1, len(words)))\n",
    "        state.stack.append(0) # ROOT\n",
    "        word_ids = []\n",
    "        for w in words:\n",
    "            if w is None:\n",
    "                continue\n",
    "            word_ids.append(word2id[w])\n",
    "        word_ids = torch.LongTensor(word_ids).to(device)\n",
    "        pos_ids = []\n",
    "        for p in pos:\n",
    "            if p is None:\n",
    "                continue\n",
    "            pos_ids.append(pos2id[p])\n",
    "        pos_ids = torch.LongTensor(pos_ids).to(device)\n",
    "        word_ids = word_ids.unsqueeze(0)\n",
    "        pos_ids = pos_ids.unsqueeze(0)\n",
    "        while len(state.buffer) > 0 or len(state.stack) > 1:\n",
    "            feats = self.extractor.get_input_representation(state)\n",
    "            feats = feats.unsqueeze(0)\n",
    "\n",
    "            model_out = self.model.forward(word_ids, pos_ids, feats)\n",
    "            probs = torch.softmax(model_out, dim=1)\n",
    "            sorted_indices = torch.argsort(probs, dim=1, descending=True)\n",
    "            sorted_indices = torch.squeeze(sorted_indices)\n",
    "            for i in range(0, len(sorted_indices)): # might have illegal actions\n",
    "                move, rel = self.id2action[sorted_indices[i].item()]\n",
    "                if move == 'shift' and len(state.buffer) > 0:\n",
    "                    state.shift()\n",
    "                    break\n",
    "                elif len(state.stack) >= 2:\n",
    "                    if move == 'left_arc' and state.stack[-2] != 0 and rel != 'root':\n",
    "                        state.left_arc(rel)\n",
    "                        break\n",
    "                    if move == 'right_arc':\n",
    "                        state.right_arc(rel)\n",
    "                        break\n",
    "\n",
    "        result = DependencyTree()\n",
    "        for h, c, r in state.deps: # head, child(dependent), relation\n",
    "            result.add_deprel(DependencyEdge(c, words[c], pos[c], h, r))\n",
    "        return result \n",
    "    \n",
    "    # compare the predicted tree with the reference tree\n",
    "    def compare_tree(self, ref_tree: DependencyTree, prediction: DependencyTree):\n",
    "        # unlabeled does not care about the relation\n",
    "        target_unlabeled = set((d.id,d.head) for d in ref_tree.deprels.values())\n",
    "        target_labeled = set((d.id,d.head,d.deprel) for d in ref_tree.deprels.values())\n",
    "        predict_unlabeled = set((d.id,d.head) for d in prediction.deprels.values())\n",
    "        predict_labeled = set((d.id,d.head,d.deprel) for d in prediction.deprels.values())\n",
    "\n",
    "        labeled_correct = len(predict_labeled.intersection(target_labeled))\n",
    "        unlabeled_correct = len(predict_unlabeled.intersection(target_unlabeled))\n",
    "        num_words = len(predict_labeled)\n",
    "        return labeled_correct, unlabeled_correct, num_words \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dep_trees: List[DependencyTree], parser: Parser):\n",
    "    total_labeled_correct = 0\n",
    "    total_unlabeled_correct = 0\n",
    "    total_words = 0\n",
    "    count = 0 \n",
    "    print(\"Evaluating.\")\n",
    "    for dtree in dep_trees:\n",
    "        words = dtree.words()\n",
    "        pos = dtree.pos()\n",
    "        prediction = parser.parse_sentence(words, pos)\n",
    "        labeled_correct, unlabeled_correct, num_words = parser.compare_tree(dtree, prediction)\n",
    "        total_labeled_correct += labeled_correct\n",
    "        total_unlabeled_correct += unlabeled_correct\n",
    "        total_words += num_words\n",
    "        count += 1 \n",
    "        if count % 200 == 0:\n",
    "            print(f'{count}/{len(dep_trees)}')\n",
    "\n",
    "    las = total_labeled_correct / float(total_words)\n",
    "    uas = total_unlabeled_correct / float(total_words)\n",
    "\n",
    "    print(f\"{len(dep_trees)} sentences.\\n\")\n",
    "    print(f\"Labeled Attachment Score: {las}\\n\")\n",
    "    print(f\"Unlabeled Attachment Score: {uas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(words, pos, feats, label, batch_size):\n",
    "    for i in range(0, len(words), batch_size):\n",
    "        batch_words = words[i:i+batch_size]\n",
    "        batch_pos = pos[i:i+batch_size]\n",
    "        batch_words = pad_sequence(batch_words, batch_first=True).to(device)\n",
    "        batch_pos = pad_sequence(batch_pos, batch_first=True).to(device)\n",
    "        \n",
    "        yield batch_words, batch_pos, feats[i:i+batch_size], label[i:i+batch_size]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = list(batchify(train_words, train_pos, train_feats, train_label, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 256)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches), len(batches[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is cuNN error, rerun\n",
    "model = BiLSTMOracle(feature_len=feature_len, word_dim=word_dim, pos_dim=pos_dim, word_emb_dim=word_emb_dim, pos_emb_dim=pos_emb_dim, out_dim=out_dim, lstm_hidden_dim=lstm_hidden_dim, mlp_hidden_dim=mlp_hidden_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        model: BiLSTMOracle,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        loss_function,\n",
    "        # train_dataloader: DataLoader,\n",
    "        batches: List[Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]],\n",
    "        log_interval=500,\n",
    "        epochs: int = 2):\n",
    "    \n",
    "    model.train()\n",
    "    dev_parser = Parser(model, LSTMFeatureExtractor())\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        epoch_loss = 0\n",
    "        # for id, (w, p ,f, batch_label) in enumerate(tqdm(train_dataloader)):\n",
    "        for id, (w, p ,f, batch_label) in enumerate(tqdm(batches)):\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(w,p,f)\n",
    "            output = output.cpu()\n",
    "            batch_label = batch_label.cpu()\n",
    "            # output:[batch_size, num_classes]\n",
    "            # label[batch_size]\n",
    "            loss = loss_function(output, batch_label)\n",
    "            total_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 0.2) # 防止梯度爆炸\n",
    "            optimizer.step()\n",
    "\n",
    "            if id % log_interval == 0 and id > 0:\n",
    "                print(\n",
    "                    \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                    \"| loss {:8.4f}\".format(\n",
    "                        epoch, id, len(batches), loss\n",
    "                    )\n",
    "                )\n",
    "                total_loss = 0\n",
    "\n",
    "        print(f'Epoch {epoch}, loss: {epoch_loss/len(batches)}')\n",
    "        print('--'*20)\n",
    "        evaluate(dev_trees[:50], dev_parser)\n",
    "        print('--'*20)\n",
    "        epoch_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM FeatureExtractor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 51/191 [00:14<00:38,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 |    50/  191 batches | loss   1.9169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 101/191 [00:28<00:21,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 |   100/  191 batches | loss   1.5207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 151/191 [00:40<00:11,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 |   150/  191 batches | loss   1.0705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:51<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 1.8020762579603344\n",
      "----------------------------------------\n",
      "Evaluating.\n",
      "50 sentences.\n",
      "\n",
      "Labeled Attachment Score: 0.2927659574468085\n",
      "\n",
      "Unlabeled Attachment Score: 0.3727659574468085\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, batches, epochs=epochs, log_interval=50)\n",
    "torch.save(model, 'dep_model_lstm_demo.pt')\n",
    "# this is just for training demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "The final model is trained using:\n",
    "- `batch_size` = 512\n",
    "- `epochs` = 2\n",
    "- `learning_rate` = 0.001\n",
    "- `word_emb_dim` = 50\n",
    "- `pos_emb_dim` = 10\n",
    "- `lstm_hidden_dim` = 30\n",
    "- `mlp_hidden_dim` = 100\n",
    "\n",
    "Note: word_emb + pos_emb = 2 * lstm_hidden_dim\n",
    "\n",
    "which takes around 1 h:)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM FeatureExtractor\n",
      "Evaluating.\n",
      "200/2416\n",
      "400/2416\n",
      "600/2416\n",
      "800/2416\n",
      "1000/2416\n",
      "1200/2416\n",
      "1400/2416\n",
      "1600/2416\n",
      "1800/2416\n",
      "2000/2416\n",
      "2200/2416\n",
      "2400/2416\n",
      "2416 sentences.\n",
      "\n",
      "Labeled Attachment Score: 0.8461294192364689\n",
      "\n",
      "Unlabeled Attachment Score: 0.8716921882718227\n"
     ]
    }
   ],
   "source": [
    "test_model = torch.load('dep_model_lstm_final.pt')\n",
    "parser = Parser(test_model, LSTMFeatureExtractor())\n",
    "evaluate(test_trees, parser)\n",
    "# this takes around 3 mins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The LAS for baseline model is `0.733`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM FeatureExtractor\n",
      "Evaluating.\n",
      "100 sentences.\n",
      "\n",
      "Labeled Attachment Score: 0.8252933507170795\n",
      "\n",
      "Unlabeled Attachment Score: 0.8609300304215558\n"
     ]
    }
   ],
   "source": [
    "test_model = torch.load('dep_model_lstm_final.pt')\n",
    "parser = Parser(test_model, LSTMFeatureExtractor())\n",
    "evaluate(test_trees[:100], parser)\n",
    "# for demonstration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
